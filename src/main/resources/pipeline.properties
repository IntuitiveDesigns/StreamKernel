# =============================================================================
#  STREAM KERNEL - ENTERPRISE PROFILE (DURABLE / CREDIBLE / PRODUCTION-LIKE)
#  Purpose:
#   - Settings that enterprise teams will accept as "real"
#   - Strong durability + producer-side de-duplication
# =============================================================================

# --- IDENTITY ---
pipeline.name=StreamKernel-Enterprise
pipeline.version=2.1.0-Stable

# --- PIPELINE CONCURRENCY ---
# Start conservatively; increase until the broker or NIC saturates and latency is stable.
pipeline.parallelism=24
pipeline.app.batch.size=1000

# --- OBSERVABILITY ---
metrics.enabled=true
metrics.type=PROMETHEUS
metrics.prometheus.port=8080

# --- SOURCE ---
source.type=MONGODB
source.synthetic.payload.size=1024
# High entropy makes compression less effective; keep false unless you explicitly want worst-case.
source.synthetic.high.entropy=false
source.topic=streamkernel-input

# --- SINK ---
sink.type=KAFKA
sink.topic=streamkernel-bench-test
sink.partitions=24

# --- TRANSFORM / CACHE ---
transform.type=NOOP
cache.type=NOOP

# =============================================================================
#  KAFKA PRODUCER TUNING (ENTERPRISE)
#  Notes:
#   - acks=all + idempotence=true gives strong durability and avoids duplicates from retries
#   - in.flight=5 is safe with idempotence enabled
# =============================================================================
kafka.broker=localhost:9092

# 1) DURABILITY / RELIABILITY (ENABLED)
kafka.producer.acks=all
kafka.producer.idempotence=true
kafka.producer.retries=2147483647
kafka.producer.delivery.timeout.ms=120000

# 2) PERFORMANCE
# lz4 is a strong default; consider zstd if you map it in code and want better compression ratios.
kafka.producer.compression=lz4
kafka.producer.max.in.flight.requests.per.connection=5

# 3) BATCHING
# Prefer moderate batching to avoid huge memory spikes and reduce tail latency.
# Start with 256KB; if your broker/network can handle it and latency targets allow, try 1MB.
kafka.producer.batch.size=262144
kafka.producer.linger.ms=10
# Container-safe starting point (256MB). Increase if you see producer buffer exhaustion.
kafka.producer.buffer.memory=268435456
# Keep aligned with expected payload sizes and batching strategy.
kafka.producer.max.request.size=10485760

# --- CONSUMER DEFAULTS (Ignored for Synthetic) ---
kafka.group.id=streamkernel-consumer-group
kafka.auto.offset.reset=earliest

dlq.type=DLQ_LOG

mongodb.uri=mongodb://localhost:27017
mongodb.database=support_db
mongodb.collection=tickets_vectorized